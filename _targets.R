# Chargement des packages nÃ©cessaires
library(targets)
library(here)
library(futile.logger)
library(geoflow)

if (!file.exists(here::here("results"))) {
  dir.create(here::here("results"))}
# Restaurer l'environnement `renv`
if (!requireNamespace("renv", quietly = TRUE)) install.packages("renv")
renv::restore()

# ðŸ”¹ SOURCING des fonctions nÃ©cessaires
targets::tar_source(here::here("tunaatlas_scripts/generation/create_global_tuna_atlas_dataset_v2023.R"))

# DÃ©finir les options globales de `{targets}`
tar_option_set(
  packages = c(
    "jsonlite", "here", "purrr", "futile.logger", "geoflow",
    "dotenv", "data.table", "dplyr", "DBI", "RPostgreSQL",
    "rpostgis", "ggplot2", "readr", "sf", "bookdown", "knitr", "tidyr"
  )
)
options(
  encoding = "UTF-8",
  stringsAsFactors = FALSE, 
  dplyr.summarise.inform = FALSE
)

Sys.setlocale("LC_ALL", "en_US.UTF-8")
# config <- initWorkflow(here::here("catch_ird_level2_local.json"))  # ðŸ”¥ Charge en dehors de `{targets}`
# entity <- config$metadata$content$entities[[1]]
# action <- entity$data$actions[[1]]
# opts <- action$options
# DÃ©finition du pipeline
list(
  tar_target(
    config,
    initWorkflow(here::here("catch_ird_level2_local.json"))  # ðŸ”¥ recrÃ©er `config` depuis le fichier
  ),
  
  tar_target(
    entity,
    {
      entityfile <- config$metadata$content$entities[[1]]
      entityfile$relations <- NULL # Pour Ã©viter l'Ã©chec lors du chargement de la codelist depuis Google Drive si non connectÃ©
      entityfile
    }
  ),
  
  tar_target(
    action,
    entity$data$actions[[1]]
  ),
  tar_target(
    opts,
    action$options
  ),
  tar_target(
    catch_file,
    {
      # ðŸ”¹ RÃ©cupÃ©ration des paramÃ¨tres de tÃ©lÃ©chargement
      key <- opts$keygeoref  
      doi <- opts$doigeoref  
      file_path <- here::here("data", key)  # Chemin du fichier cible
      
      # ðŸ”¹ VÃ©rification si le fichier existe dÃ©jÃ 
      if (!file.exists(file_path)) {
        zen4R::download_zenodo(doi = doi, files = key, path = here::here("data"))
      }
      
      # ðŸ”¹ Retourne le chemin du fichier (existant ou tÃ©lÃ©chargÃ©)
      file_path
    },
    format = "file"
  ),
  
  tar_target(
    nominal_catch_file,
    {
      # ðŸ”¹ RÃ©cupÃ©ration des paramÃ¨tres de tÃ©lÃ©chargement
      keynominal <- opts$keynominal  
      doinominal <- opts$doinominal  
      file_path <- here::here("data", keynominal)  # DÃ©finition du chemin attendu
      
      # ðŸ”¹ VÃ©rification si le fichier existe dÃ©jÃ 
      if (!file.exists(file_path)) {
        zen4R::download_zenodo(doi = doinominal, files = keynominal, path = here::here("data"))
      }
      
      # ðŸ”¹ Retourne le chemin du fichier
      file_path
    },
    format = "file"
  ),
  # ðŸ”¹ 3. ExÃ©cuter `create_global_tuna_atlas_dataset_v2023()` avec cette entitÃ©
  tar_target(
    results_file,
    {
      flog.info("Traitement de l'entitÃ© : %s", entity$identifiers[["id"]])
      
      # ðŸ”¹ Ajout explicite des fichiers pour crÃ©er une dÃ©pendance
      nominal_catch <- nominal_catch_file  
      catch <- catch_file  
      create_global_tuna_atlas_dataset_v2023(action, entity, config)
      
      output_file <- file.path("data", paste0(entity$identifiers[["id"]], "_harmonized.csv"))
      
      if (file.exists(output_file)) {
        flog.info("Fichier gÃ©nÃ©rÃ© avec succÃ¨s : %s", output_file)
        output_file
      } else {
        flog.error("Le fichier attendu n'a pas Ã©tÃ© gÃ©nÃ©rÃ© : %s", output_file)
        stop("Erreur : fichier non gÃ©nÃ©rÃ©")
      }
    },
    format = "file"
  ),
  # ðŸ”¹ 4. Lire et sauvegarder le fichier gÃ©nÃ©rÃ©
  tar_target(
    save_results,
    {
      df <- read.csv(results_file)  # Lire le fichier gÃ©nÃ©rÃ©

      write.csv(df, here::here("results/tuna_atlas_results.csv"))  # Sauvegarde finale
      "results/tuna_atlas_results.csv"
    },
    format = "file"
  )
)
# # DÃ©finition du pipeline
# list(
#   # ðŸ”¹ 1. Charger la configuration JSON
#   tar_target(
#     config,
#     initWorkflow(here::here("catch_ird_level2_local.json")),  # ðŸ”¥ Chargement direct de lâ€™objet R6
#     format = "rds"  # ðŸ’¡ On utilise "rds" pour Ã©viter que `{targets}` ne modifie l'objet
#   ),
#   tar_target(
#     entity,
#     config$metadata$content$entities,  # ðŸ”¥ On prend directement la liste d'entitÃ©s
#     pattern = map(config)
#   ),tar_target(
#     actions,
#     entity$data$actions[[1]],  # ðŸ”¥ Toujours la premiÃ¨re action
#     pattern = map(entity)
#   ),
#   tar_target(
#     results_files,
#     {
#       flog.info("Traitement de l'entitÃ© : %s", entity$identifiers[["id"]])
#       flog.info("Traitement de l'action : %s", actions)
#       
#       create_global_tuna_atlas_dataset_v2023(actions, entity, config)  # ðŸ”¥ `config` reste un objet R6
#       
#       output_file <- file.path("data", paste0(entity$identifiers[["id"]], "_harmonized.csv"))
#       
#       if (file.exists(output_file)) {
#         flog.info("Fichier gÃ©nÃ©rÃ© avec succÃ¨s : %s", output_file)
#         output_file
#       } else {
#         flog.error("Le fichier attendu n'a pas Ã©tÃ© gÃ©nÃ©rÃ© : %s", output_file)
#         stop("Erreur : fichier non gÃ©nÃ©rÃ©")
#       }
#     },
#     pattern = map(entity, actions),
#     format = "file"
#   ),
#   
#   # ðŸ”¹ 6. Regrouper les fichiers en une liste pour Ã©viter de brancher sur un pattern
#   tar_target(
#     results_list,
#     results_files
#   ),
#   
#   # ðŸ”¹ 7. Lire et sauvegarder les rÃ©sultats
#   tar_target(
#     save_results,
#     {
#       df_list <- lapply(results_list, read.csv)
#       df_final <- do.call(rbind, df_list)
#       
#       write.csv(df_final, "results/tuna_atlas_results.csv")
#       "results/tuna_atlas_results.csv"
#     },
#     format = "file"
#   )
# )
