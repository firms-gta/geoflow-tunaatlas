# Chargement des packages nÃ©cessaires
library(targets)
library(here)
library(futile.logger)
library(geoflow)

if (!file.exists(here::here("results"))) {
  dir.create(here::here("results"))}
if (!file.exists(here::here("data"))) {
  dir.create(here::here("data"))}
# Restaurer l'environnement `renv`
if (!requireNamespace("renv", quietly = TRUE)) install.packages("renv")
renv::restore()

# ðŸ”¹ SOURCING des fonctions nÃ©cessaires
targets::tar_source(here::here("tunaatlas_scripts/generation/create_global_tuna_atlas_dataset_v2025.R"))

# DÃ©finir les options globales de `{targets}`
tar_option_set(
  packages = c(
    "jsonlite", "here", "purrr", "futile.logger", "geoflow",
    "dotenv", "data.table", "dplyr", "DBI", "RPostgreSQL",
    "rpostgis", "ggplot2", "readr", "sf", "bookdown", "knitr", "tidyr", "CWP.dataset", "utils", "ows4R", "callr"
  )
)
options(
  encoding = "UTF-8",
  stringsAsFactors = FALSE, 
  dplyr.summarise.inform = FALSE
)

Sys.setlocale("LC_ALL", "en_US.UTF-8")
# config <- initWorkflow(here::here("catch_ird_level2_local.json"))  # 
# entity <- config$metadata$content$entities[[1]]
# action <- entity$data$actions[[1]]
# opts <- action$options
# DÃ©finition du pipeline
list(
  tar_target(
    config,
    initWorkflow(here::here("catch_ird_level2_local.json"))  #
  ),
  
  tar_target(
    entity,
    {
      entityfile <- config$metadata$content$entities[[1]]
      entityfile$relations <- NULL # Pour Ã©viter l'Ã©chec lors du chargement de la codelist depuis Google Drive si non connectÃ©
      entityfile
    }
  ),
  
  tar_target(
    action,
    entity$data$actions[[1]]
  ),
  tar_target(
    opts,
    action$options
  ),
  tar_target(
    nominal_catch_file,
    {
      # ðŸ”¹ RÃ©cupÃ©ration des paramÃ¨tres de tÃ©lÃ©chargement
      keynominal <- opts$keynominal  
      doinominal <- opts$doinominal  
      file_path <- here::here("data", keynominal)  # DÃ©finition du chemin attendu
      
      # ðŸ”¹ VÃ©rification si le fichier existe dÃ©jÃ 
      if (!file.exists(file_path)) {
        zen4R::download_zenodo(doi = doinominal, files = keynominal, path = here::here("data"))
      }
      
      # ðŸ”¹ Retourne le chemin du fichier
      file_path
    },
    format = "file"
  )
  # ,
  # tar_target(
  #   all_raw_data,
  #   {
  #     # 1) PrÃ©pare le dossier et le chemin du ZIP
  #     zipfile <- file.path("data", "All_rawdata_for_level2.zip")
  #     url     <- "https://zenodo.org/record/15496164/files/All_rawdata_for_level2.zip"
  # 
  #     # 2) TÃ©lÃ©charge si nÃ©cessaire
  #     if (!file.exists(zipfile)) {
  #       utils::download.file(url, zipfile, mode = "wb")
  #     }
  # 
  #     # 3) DÃ©zippe si pas dÃ©jÃ  dÃ©compressÃ©
  #     files_in_data <- list.files("data", all.files = TRUE, no.. = TRUE)
  #     # on considÃ¨re qu'il est dÃ©jÃ  dÃ©compressÃ© s'il y a au moins un fichier qui n'est pas le ZIP
  #     need_unzip <- !any(!grepl("\\.zip$", files_in_data))
  #     if (need_unzip) {
  #       unzip(zipfile, exdir = "data")
  #     }
  # 
  #     # 4) On renvoie la liste des fichiers extraits
  #     list.files("data", full.names = TRUE)
  #   },
  #   format = "file"
  # )
  ,
  # ðŸ”¹ 3. ExÃ©cuter `create_global_tuna_atlas_dataset_v2025()` avec cette entitÃ©
  tar_target(
    results_file,
    {
      flog.info("Traitement de l'entitÃ© : %s", entity$identifiers[["id"]])

      # ðŸ”¹ Ajout explicite des fichiers pour crÃ©er une dÃ©pendance
      nominal_catch <- nominal_catch_file
      create_global_tuna_atlas_dataset_v2025(action, entity, config)

      output_file <- file.path("data", paste0(entity$identifiers[["id"]], "_harmonized.csv"))

      if (file.exists(output_file)) {
        flog.info("Fichier gÃ©nÃ©rÃ© avec succÃ¨s : %s", output_file)
        output_file
      } else {
        flog.error("Le fichier attendu n'a pas Ã©tÃ© gÃ©nÃ©rÃ© : %s", output_file)
        stop("Erreur : fichier non gÃ©nÃ©rÃ©")
      }
    },
    format = "file"
  )
  # ,
  # # ðŸ”¹ 4. Lire et sauvegarder le fichier gÃ©nÃ©rÃ©
  # tar_target(
  #   save_results,
  #   {
  #     df <- read.csv(results_file)  # Lire le fichier gÃ©nÃ©rÃ©
  # 
  #     write.csv(df, here::here("results/tuna_atlas_results.csv"))  # Sauvegarde finale
  #     "results/tuna_atlas_results.csv"
  #   },
  #   format = "file"
  # )
  # ,
  # tar_target(
  #   markdown_report,
  #   {
  #     # rÃ©pertoire racine de votre projet
  #     main_dir <- here::here()
  #     # connexion Ã  la BDD
  #     con <- config$software$output$dbi
  #     
  #     # gÃ©nÃ©ration du rapport "court"
  #     CWP.dataset::summarising_step(
  #       main_dir             = main_dir,
  #       connectionDB         = con,
  #       config               = config,
  #       sizepdf              = "short",
  #       savestep             = TRUE,
  #       usesave              = TRUE,
  #       source_authoritylist = "all"
  #     )
  #     
  #     # gÃ©nÃ©ration du rapport "moyen"
  #     CWP.dataset::summarising_step(
  #       main_dir             = main_dir,
  #       connectionDB         = con,
  #       config               = config,
  #       sizepdf              = "middle",
  #       savestep             = TRUE,
  #       usesave              = TRUE,
  #       source_authoritylist = "all",
  #       fast_and_heavy       = FALSE
  #     )
  #     
  #     # 2) on liste les PDF produits
  #     pdfs <- list.files(
  #       path       = file.path(main_dir, "_book"), # ou le dossier oÃ¹ sont crÃ©Ã©s les PDF
  #       pattern    = "\\.(pdf)$",
  #       full.names = TRUE
  #     )
  #     
  #     # on renvoie la liste des chemins produits
  #     pdfs
  #   },
  #   format = "file"
  # )
)
# # DÃ©finition du pipeline
# list(
#   # ðŸ”¹ 1. Charger la configuration JSON
#   tar_target(
#     config,
#     initWorkflow(here::here("catch_ird_level2_local.json")),  # ðŸ”¥ Chargement direct de lâ€™objet R6
#     format = "rds"  # ðŸ’¡ On utilise "rds" pour Ã©viter que `{targets}` ne modifie l'objet
#   ),
#   tar_target(
#     entity,
#     config$metadata$content$entities,  # ðŸ”¥ On prend directement la liste d'entitÃ©s
#     pattern = map(config)
#   ),tar_target(
#     actions,
#     entity$data$actions[[1]],  # ðŸ”¥ Toujours la premiÃ¨re action
#     pattern = map(entity)
#   ),
#   tar_target(
#     results_files,
#     {
#       flog.info("Traitement de l'entitÃ© : %s", entity$identifiers[["id"]])
#       flog.info("Traitement de l'action : %s", actions)
#       
#       create_global_tuna_atlas_dataset_v2023(actions, entity, config)  # ðŸ”¥ `config` reste un objet R6
#       
#       output_file <- file.path("data", paste0(entity$identifiers[["id"]], "_harmonized.csv"))
#       
#       if (file.exists(output_file)) {
#         flog.info("Fichier gÃ©nÃ©rÃ© avec succÃ¨s : %s", output_file)
#         output_file
#       } else {
#         flog.error("Le fichier attendu n'a pas Ã©tÃ© gÃ©nÃ©rÃ© : %s", output_file)
#         stop("Erreur : fichier non gÃ©nÃ©rÃ©")
#       }
#     },
#     pattern = map(entity, actions),
#     format = "file"
#   ),
#   
#   # ðŸ”¹ 6. Regrouper les fichiers en une liste pour Ã©viter de brancher sur un pattern
#   tar_target(
#     results_list,
#     results_files
#   ),
#   
#   # ðŸ”¹ 7. Lire et sauvegarder les rÃ©sultats
#   tar_target(
#     save_results,
#     {
#       df_list <- lapply(results_list, read.csv)
#       df_final <- do.call(rbind, df_list)
#       
#       write.csv(df_final, "results/tuna_atlas_results.csv")
#       "results/tuna_atlas_results.csv"
#     },
#     format = "file"
#   )
# )
